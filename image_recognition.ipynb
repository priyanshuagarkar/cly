{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.11.0\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import os.path\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img,img_to_array\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["# Create a list with the filepaths for training and testing\n","train_dir = Path('archive/train')\n","train_filepaths = list(train_dir.glob(r'**/*.jpg'))"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["test_dir = Path('archive/test')\n","test_filepaths = list(test_dir.glob(r'**/*.jpg'))"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["val_dir = Path('archive/validation')\n","val_filepaths = list(test_dir.glob(r'**/*.jpg'))"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def image_processing(filepath):\n","    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n","    \"\"\"\n","\n","    labels = [str(filepath[i]).split(\"/\")[-2] \\\n","              for i in range(len(filepath))]\n","\n","    filepath = pd.Series(filepath, name='Filepath').astype(str)\n","    labels = pd.Series(labels, name='Label')\n","\n","    # Concatenate filepaths and labels\n","    df = pd.concat([filepath, labels], axis=1)\n","\n","    # Shuffle the DataFrame and reset index\n","    df = df.sample(frac=1).reset_index(drop = True)\n","    \n","    return df"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df \u001b[39m=\u001b[39m image_processing(train_filepaths)\n\u001b[0;32m      2\u001b[0m test_df \u001b[39m=\u001b[39m image_processing(test_filepaths)\n\u001b[0;32m      3\u001b[0m val_df \u001b[39m=\u001b[39m image_processing(val_filepaths)\n","Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mimage_processing\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimage_processing\u001b[39m(filepath):\n\u001b[0;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Create a DataFrame with the filepath and the labels of the pictures\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     labels \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(filepath[i])\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \\\n\u001b[0;32m      6\u001b[0m               \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(filepath))]\n\u001b[0;32m      8\u001b[0m     filepath \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(filepath, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFilepath\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[0;32m      9\u001b[0m     labels \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(labels, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimage_processing\u001b[39m(filepath):\n\u001b[0;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Create a DataFrame with the filepath and the labels of the pictures\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     labels \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39;49m(filepath[i])\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m] \\\n\u001b[0;32m      6\u001b[0m               \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(filepath))]\n\u001b[0;32m      8\u001b[0m     filepath \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(filepath, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFilepath\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[0;32m      9\u001b[0m     labels \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(labels, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mIndexError\u001b[0m: list index out of range"]}],"source":["train_df = image_processing(train_filepaths)\n","test_df = image_processing(test_filepaths)\n","val_df = image_processing(val_filepaths)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print('-- Training set --\\n')\n","print(f'Number of pictures: {train_df.shape[0]}\\n')\n","print(f'Number of different labels: {len(train_df.Label.unique())}\\n')\n","print(f'Labels: {train_df.Label.unique()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a DataFrame with one Label of each category\n","df_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n","\n","# Display some pictures of the dataset\n","fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n","                        subplot_kw={'xticks': [], 'yticks': []})\n","\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(plt.imread(df_unique.Filepath[i]))\n","    ax.set_title(df_unique.Label[i], fontsize = 12)\n","plt.tight_layout(pad=0.5)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",")\n","\n","test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_images = train_generator.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='Filepath',\n","    y_col='Label',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=32,\n","    shuffle=True,\n","    seed=0,\n","    rotation_range=30,\n","    zoom_range=0.15,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_images = train_generator.flow_from_dataframe(\n","    dataframe=val_df,\n","    x_col='Filepath',\n","    y_col='Label',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=32,\n","    shuffle=True,\n","    seed=0,\n","    rotation_range=30,\n","    zoom_range=0.15,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_images = test_generator.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='Filepath',\n","    y_col='Label',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=32,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pretrained_model = tf.keras.applications.MobileNetV2(\n","    input_shape=(224, 224, 3),\n","    include_top=False,\n","    weights='imagenet',\n","    pooling='avg'\n",")\n","pretrained_model.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["inputs = pretrained_model.input\n","\n","x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n","x = tf.keras.layers.Dense(128, activation='relu')(x)\n","\n","outputs = tf.keras.layers.Dense(36, activation='softmax')(x)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model.fit(\n","    train_images,\n","    validation_data=val_images,\n","    batch_size = 32,\n","    epochs=5,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor='val_loss',\n","            patience=2,\n","            restore_best_weights=True\n","        )\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Predict the label of the test_images\n","pred = model.predict(test_images)\n","pred = np.argmax(pred,axis=1)\n","# Map the label\n","labels = (train_images.class_indices)\n","labels = dict((v,k) for k,v in labels.items())\n","pred1 = [labels[k] for k in pred]\n","pred1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def output(location):\n","    img=load_img(location,target_size=(224,224,3))\n","    img=img_to_array(img)\n","    img=img/255\n","    img=np.expand_dims(img,[0])\n","    answer=model.predict(img)\n","    y_class = answer.argmax(axis=-1)\n","    y = \" \".join(str(x) for x in y_class)\n","    y = int(y)\n","    res = labels[y]\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img = output('/kaggle/input/images/test/apple/Image_1.jpg')\n","img"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save('FV.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
